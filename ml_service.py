from gradio_client import Client
from typing import Dict, Any, Optional
import logging
from models import CategoriaGasto

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MLService:
    """Servicio para interactuar con el modelo de Machine Learning en Hugging Face"""
    
    def __init__(self):
        self.client = None
        self.model_space = "cristiandiaz2403/MiSpace"
        self._initialize_client()
    
    def _initialize_client(self):
        """Inicializar el cliente de Gradio"""
        try:
            self.client = Client(self.model_space)
            logger.info(f"Cliente ML inicializado correctamente para {self.model_space}")
        except Exception as e:
            logger.error(f"Error al inicializar cliente ML: {str(e)}")
            self.client = None
    
    def obtener_sugerencia_categoria(self, descripcion: str, categoria_usuario: str) -> Dict[str, Any]:
        """
        Obtener sugerencia de categor√≠a del modelo ML
        
        Args:
            descripcion: Descripci√≥n del gasto
            categoria_usuario: Categor√≠a elegida por el usuario
            
        Returns:
            Diccionario con la respuesta del modelo y metadatos
        """
        if not self.client:
            logger.warning("Cliente ML no disponible, reintentar inicializaci√≥n")
            self._initialize_client()
            
        if not self.client:
            return self._respuesta_fallback(descripcion, categoria_usuario)
        
        try:
            # Validar que la categor√≠a del usuario sea v√°lida
            categorias_validas = ['comida', 'transporte', 'varios']
            if categoria_usuario.lower() not in categorias_validas:
                categoria_usuario = 'varios'  # Categor√≠a por defecto
            
            # Llamar al modelo
            result = self.client.predict(
                descripcion=descripcion,
                categoria_usuario=categoria_usuario.lower(),
                api_name="/predict"
            )
            
            logger.info(f"Predicci√≥n exitosa para descripci√≥n: '{descripcion[:50]}...'")
            
            return {
                "exito": True,
                "prediccion_modelo": result,
                "categoria_original": categoria_usuario,
                "descripcion": descripcion,
                "recomendacion": self._interpretar_resultado(result, categoria_usuario),
                "confianza": self._calcular_confianza(result, categoria_usuario)
            }
            
        except Exception as e:
            logger.error(f"Error en predicci√≥n ML: {str(e)}")
            return self._respuesta_fallback(descripcion, categoria_usuario, error=str(e))
    
    def _interpretar_resultado(self, resultado: Any, categoria_original: str) -> Dict[str, Any]:
        """
        Interpretar el resultado del modelo y generar una recomendaci√≥n clara
        """
        try:
            # Si el resultado es un string, intentar parsearlo como categor√≠a
            if isinstance(resultado, str):
                categoria_sugerida = resultado.lower().strip()
                
                # Mapear posibles respuestas del modelo a nuestras categor√≠as
                mapeo_categorias = {
                    'comida': 'comida',
                    'food': 'comida',
                    'alimentacion': 'comida',
                    'restaurante': 'comida',
                    'transporte': 'transporte',
                    'transport': 'transporte',
                    'viaje': 'transporte',
                    'taxi': 'transporte',
                    'bus': 'transporte',
                    'varios': 'varios',
                    'other': 'varios',
                    'others': 'varios',
                    'miscellaneous': 'varios'
                }
                
                categoria_final = mapeo_categorias.get(categoria_sugerida, categoria_original)
                
                return {
                    "categoria_sugerida": categoria_final,
                    "categoria_original": categoria_original,
                    "coincide": categoria_final == categoria_original.lower(),
                    "mensaje": self._generar_mensaje_recomendacion(categoria_final, categoria_original)
                }
            
            # Si es un diccionario o estructura m√°s compleja
            elif isinstance(resultado, (dict, list)):
                return {
                    "categoria_sugerida": categoria_original,
                    "categoria_original": categoria_original,
                    "coincide": True,
                    "mensaje": "El modelo proporcion√≥ una respuesta compleja. Se mantiene la categor√≠a original.",
                    "resultado_raw": resultado
                }
            
            else:
                return {
                    "categoria_sugerida": categoria_original,
                    "categoria_original": categoria_original,
                    "coincide": True,
                    "mensaje": "Se mantiene la categor√≠a original."
                }
                
        except Exception as e:
            logger.error(f"Error interpretando resultado: {str(e)}")
            return {
                "categoria_sugerida": categoria_original,
                "categoria_original": categoria_original,
                "coincide": True,
                "mensaje": "Error en interpretaci√≥n. Se mantiene la categor√≠a original."
            }
    
    def _generar_mensaje_recomendacion(self, categoria_sugerida: str, categoria_original: str) -> str:
        """Generar mensaje de recomendaci√≥n basado en la comparaci√≥n"""
        if categoria_sugerida == categoria_original.lower():
            return f"‚úÖ Excelente elecci√≥n! La categor√≠a '{categoria_original}' es la m√°s apropiada para este gasto."
        else:
            return f"üí° Sugerencia: Considera cambiar de '{categoria_original}' a '{categoria_sugerida}' para una mejor clasificaci√≥n."
    
    def _calcular_confianza(self, resultado: Any, categoria_original: str) -> float:
        """Calcular un nivel de confianza b√°sico"""
        try:
            if isinstance(resultado, str):
                # Si coincide con la categor√≠a original, alta confianza
                if resultado.lower().strip() == categoria_original.lower():
                    return 0.9
                # Si es una categor√≠a v√°lida diferente, confianza media
                elif resultado.lower().strip() in ['comida', 'transporte', 'varios']:
                    return 0.75
                else:
                    return 0.5
            else:
                return 0.6  # Confianza por defecto para resultados no string
        except:
            return 0.5
    
    def _respuesta_fallback(self, descripcion: str, categoria_usuario: str, error: str = None) -> Dict[str, Any]:
        """Respuesta de respaldo cuando el modelo no est√° disponible"""
        return {
            "exito": False,
            "error": error or "Servicio de ML no disponible",
            "categoria_original": categoria_usuario,
            "descripcion": descripcion,
            "recomendacion": {
                "categoria_sugerida": categoria_usuario,
                "categoria_original": categoria_usuario,
                "coincide": True,
                "mensaje": "üîß Servicio de ML temporalmente no disponible. Se mantiene tu categor√≠a elegida."
            },
            "confianza": 1.0  # Alta confianza en la elecci√≥n del usuario cuando ML no est√° disponible
        }
    
    def probar_conexion(self) -> Dict[str, Any]:
        """Probar la conexi√≥n con el modelo"""
        try:
            resultado = self.obtener_sugerencia_categoria("test comida hamburguesa", "comida")
            return {
                "disponible": resultado["exito"],
                "modelo": self.model_space,
                "respuesta_test": resultado
            }
        except Exception as e:
            return {
                "disponible": False,
                "modelo": self.model_space,
                "error": str(e)
            }

# Instancia global del servicio
ml_service = MLService()
